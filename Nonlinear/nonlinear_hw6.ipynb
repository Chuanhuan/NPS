{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYP437wZ155q"
      },
      "source": [
        "# Q1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h18yoxXYNt0X",
        "outputId": "b19c9c30-5bb1-497b-bf13-cfceca2e8b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 1 iteration: a=0 and b=2.501\n",
            "The 2 iteration: a=0 and b=1.2514999999999998\n",
            "The 3 iteration: a=0.6247499999999999 and b=1.2514999999999998\n",
            "The 4 iteration: a=0.6247499999999999 and b=0.9391249999999999\n",
            "The 5 iteration: a=0.6247499999999999 and b=0.7829375\n",
            "The 6 iteration: a=0.7028437499999999 and b=0.7829375\n",
            "The 7 iteration: a=0.7028437499999999 and b=0.7438906249999999\n",
            "The 8 iteration: a=0.7028437499999999 and b=0.7243671874999998\n",
            "The 9 iteration: a=0.7126054687499999 and b=0.7243671874999998\n",
            "The 10 iteration: a=0.7126054687499999 and b=0.7194863281249998\n",
            "Minimum value: 2.458297 at x = 0.716046\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "def dichotomous_search(func, a, b, epsilon=1e-3, max_iterations=100):\n",
        "    \"\"\"\n",
        "    Finds the minimum of a function within the interval [a, b].\n",
        "\n",
        "    Parameters:\n",
        "        func: Callable function representing the objective function.\n",
        "        a, b: Interval endpoints.\n",
        "        epsilon: Desired accuracy (default: 1e-6).\n",
        "        max_iterations: Maximum number of iterations (default: 100).\n",
        "\n",
        "    Returns:\n",
        "        Approximate minimum value and corresponding x-coordinate.\n",
        "    \"\"\"\n",
        "    for i in range(max_iterations):\n",
        "        c = (a + b) / 2 - epsilon\n",
        "        d = (a + b) / 2 + epsilon\n",
        "\n",
        "        fc = func(c)\n",
        "        fd = func(d)\n",
        "\n",
        "        if fc < fd:\n",
        "            b = d\n",
        "        else:\n",
        "            a = c\n",
        "        print(f'The {i+1} iteration: a={a} and b={b}')\n",
        "        if b - a < 0.01:\n",
        "            break\n",
        "\n",
        "    x_min = (a + b) / 2\n",
        "    return func(x_min), x_min\n",
        "\n",
        "# Example usage:\n",
        "def quadratic_function(x):\n",
        "    return 6*math.e**(-2*x) + 2*x**2\n",
        "\n",
        "min_value, min_x = dichotomous_search(quadratic_function, 0, 5)\n",
        "print(f\"Minimum value: {min_value:.6f} at x = {min_x:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBKswujt2LkV"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLQmHGJSOsCi",
        "outputId": "35d98fb8-4245-41e3-a203-0780682643ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 1 interation: x=0.6120317958873742, minimum value: 2.5133632760510425\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Q3(a)\n",
        "def newton_method(derivative, double_derivative , x0, a, b, tol=1e-3, max_iterations=5):\n",
        "    x = x0\n",
        "    for i in range(max_iterations):\n",
        "        # f_x = func(x)\n",
        "        f_prime_x = derivative(x)\n",
        "        f_double_prime_x = double_derivative(x)\n",
        "        x -= f_prime_x / f_double_prime_x\n",
        "        print(f'The {i+1} interation: x={x}, minimum value: {quadratic_function(x)}')\n",
        "        if x >b or x<b:\n",
        "\n",
        "            break\n",
        "        if abs(f_prime_x) < tol:\n",
        "            break\n",
        "    return x\n",
        "\n",
        "# Derivative function\n",
        "def derivative_quadratic(x):\n",
        "    return -12*math.e**(-2*x) + 4*x\n",
        "\n",
        "def double_derivative_quadratic(x):\n",
        "    return 24*math.e**(-2*x) + 4\n",
        "\n",
        "initial_guess = 1.0\n",
        "\n",
        "# Apply Newton's method\n",
        "root = newton_method(quadratic_function, double_derivative_quadratic, initial_guess, 0, 5)\n",
        "\n",
        "# print(f\"Root found: x = {root:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G61zTXITrhQ",
        "outputId": "bd71c522-b6aa-4551-8fc0-567f7c2345b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The midpoint: 2.5, minimum value: 12.540427681994514\n",
            "The midpoint: 1.25, minimum value: 3.617509991743393\n",
            "The midpoint: 0.625, minimum value: 2.5002787811611404\n",
            "The midpoint: 0.625, minimum value: 2.5002787811611404\n",
            "The midpoint: 0.625, minimum value: 2.5002787811611404\n",
            "Approximated root: x = 0.625000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Q3(b)\n",
        "def my_bisection(f, a, b, tol , max_iterations=5):\n",
        "    \"\"\"\n",
        "    Approximates a root of the function f within the interval [a, b]\n",
        "    to within a specified tolerance |f(a+b/2)| < tol.\n",
        "\n",
        "    Args:\n",
        "        f: The function for which we want to find the root.\n",
        "        a, b: Interval endpoints.\n",
        "        tol: Tolerance (desired accuracy).\n",
        "\n",
        "    Returns:\n",
        "        Approximated root.\n",
        "    \"\"\"\n",
        "    # Check if a and b bound a root\n",
        "    # if f(a) * f(b) >= 0:\n",
        "    #     raise Exception(\"The scalars a and b do not bound a root\")\n",
        "\n",
        "    # while abs((b-a) / 2) >= tol:\n",
        "    for i in range(max_iterations):\n",
        "        m = (a + b) / 2  # Midpoint\n",
        "        print(f'The midpoint: {m}, minimum value: {quadratic_function(m)}')\n",
        "        if derivative_quadratic(m) < 0:\n",
        "            b = b  # Update b\n",
        "        else:\n",
        "            b = m  # Update a\n",
        "        if derivative_quadratic(m)==0:\n",
        "            break\n",
        "\n",
        "    return (a + b) / 2\n",
        "\n",
        "\n",
        "\n",
        "# Find the root of the quadratic function within [0, 2] with tolerance 0.01\n",
        "root_approx = my_bisection(quadratic_function, 0, 5, 0.001)\n",
        "print(f\"Approximated root: x = {root_approx:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQcrVETmDVlX"
      },
      "source": [
        "# Q4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy0pQKM9VMrC",
        "outputId": "e80efb85-829e-4b22-88de-f8eda7087246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum point: [2.21875 5.     ]\n",
            "Minimum value: 0.6520147323608398\n",
            "Iterations: 15\n"
          ]
        }
      ],
      "source": [
        "# Q4(a)\n",
        "import numpy as np\n",
        "\n",
        "def cyclic_coordinate_method(func, x0, tol=0.2, max_iter=1000):\n",
        "    \"\"\"\n",
        "    Cyclic coordinate method for function minimization.\n",
        "\n",
        "    Parameters:\n",
        "    - func: The function to minimize.\n",
        "    - x0: Initial guess (numpy array).\n",
        "    - tol: Tolerance for stopping criteria.\n",
        "    - max_iter: Maximum number of iterations.\n",
        "\n",
        "    Returns:\n",
        "    - x: The estimated minimum point.\n",
        "    - fval: The function value at the minimum point.\n",
        "    - n_iter: Number of iterations performed.\n",
        "    \"\"\"\n",
        "    def line_search(func, x, direction):\n",
        "        # Simple line search that finds a step size that minimizes func along a direction\n",
        "        alpha = 1.0\n",
        "        c = 0.5\n",
        "        tau = 0.5\n",
        "        while func(x + alpha * direction) > func(x) + c * alpha * np.dot(direction, direction):\n",
        "            alpha *= tau\n",
        "        return alpha\n",
        "\n",
        "    x = np.array(x0, dtype=float)\n",
        "    n = len(x)\n",
        "    n_iter = 0\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        x_old = np.copy(x)\n",
        "        for i in range(n):\n",
        "            direction = np.zeros(n)\n",
        "            direction[i] = 1.0\n",
        "            alpha = line_search(func, x, direction)\n",
        "            x = x + alpha * direction\n",
        "        n_iter += 1\n",
        "        if np.linalg.norm(x - x_old) < tol:\n",
        "            break\n",
        "\n",
        "    fval = func(x)\n",
        "    return x, fval, n_iter\n",
        "\n",
        "# Example usage:\n",
        "def example_func(x):\n",
        "    return (3-x[0])**2 + 7*(x[1]-x[0]**2)**2\n",
        "x0 = [0.0, 0.0]\n",
        "min_point, min_value, iterations = cyclic_coordinate_method(example_func, x0)\n",
        "\n",
        "print(f\"Minimum point: {min_point}\")\n",
        "print(f\"Minimum value: {min_value}\")\n",
        "print(f\"Iterations: {iterations}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3-pldC-VQFn",
        "outputId": "348fbc1b-9c14-4cd8-dc45-074b04846dea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum point: [1.02482247 0.96203168]\n",
            "Minimum value: 3.9558172773906515\n",
            "Iterations: 1000\n"
          ]
        }
      ],
      "source": [
        "# Q4(b)\n",
        "import numpy as np\n",
        "\n",
        "def dfp_method(func, grad, x0, tol=0.2, max_iter=1000):\n",
        "    \"\"\"\n",
        "    Davidon-Fletcher-Powell (DFP) method for function minimization.\n",
        "\n",
        "    Parameters:\n",
        "    - func: The function to minimize.\n",
        "    - grad: The gradient of the function.\n",
        "    - x0: Initial guess (numpy array).\n",
        "    - tol: Tolerance for stopping criteria.\n",
        "    - max_iter: Maximum number of iterations.\n",
        "\n",
        "    Returns:\n",
        "    - x: The estimated minimum point.\n",
        "    - fval: The function value at the minimum point.\n",
        "    - n_iter: Number of iterations performed.\n",
        "    \"\"\"\n",
        "    x = np.array(x0, dtype=float)\n",
        "    n = len(x)\n",
        "    B = np.eye(n)\n",
        "    n_iter = 0\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        g = grad(x)\n",
        "        if np.linalg.norm(g) < tol:\n",
        "            break\n",
        "\n",
        "        p = -B.dot(g)\n",
        "\n",
        "        # Line search for an appropriate step size\n",
        "        alpha = line_search(func, grad, x, p)\n",
        "\n",
        "        x_new = x + alpha * p\n",
        "        g_new = grad(x_new)\n",
        "\n",
        "        s = x_new - x\n",
        "        y = g_new - g\n",
        "\n",
        "        Bs = B.dot(s)\n",
        "        sy = s.dot(y)\n",
        "\n",
        "        B += np.outer(y, y) / sy - np.outer(Bs, Bs) / s.dot(Bs)\n",
        "\n",
        "        x = x_new\n",
        "        n_iter += 1\n",
        "\n",
        "    fval = func(x)\n",
        "    return x, fval, n_iter\n",
        "\n",
        "def line_search(func, grad, x, p, alpha0=1.0, c=1e-4, tau=0.9):\n",
        "    \"\"\"\n",
        "    Backtracking line search to find an appropriate step size.\n",
        "\n",
        "    Parameters:\n",
        "    - func: The function to minimize.\n",
        "    - grad: The gradient of the function.\n",
        "    - x: Current point.\n",
        "    - p: Search direction.\n",
        "    - alpha0: Initial step size.\n",
        "    - c: Parameter for Armijo condition.\n",
        "    - tau: Reduction factor for step size.\n",
        "\n",
        "    Returns:\n",
        "    - alpha: Step size.\n",
        "    \"\"\"\n",
        "    alpha = alpha0\n",
        "    while func(x + alpha * p) > func(x) + c * alpha * grad(x).dot(p):\n",
        "        alpha *= tau\n",
        "    return alpha\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "def example_grad(x):\n",
        "    return np.array([-2*(3-x[0]) -28*x[0]*(x[1]-x[0]**2) , 14*(x[1] -x[0]**2) ])\n",
        "\n",
        "x0 = [0.0, 0.0]\n",
        "min_point, min_value, iterations = dfp_method(example_func, example_grad, x0)\n",
        "\n",
        "print(f\"Minimum point: {min_point}\")\n",
        "print(f\"Minimum value: {min_value}\")\n",
        "print(f\"Iterations: {iterations}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcXz6OWhB1t6",
        "outputId": "a282b7e4-d9e8-4332-c901-800be670f9be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Steepest Descent Method:\n",
            "Minimum point: [1.90290266 3.61647335]\n",
            "Minimum value: 1.2037684577092336\n",
            "Iterations: 278\n"
          ]
        }
      ],
      "source": [
        "# Q4(c)\n",
        "import numpy as np\n",
        "\n",
        "def steepest_descent(func, grad, x0, tol=2, max_iter=1000):\n",
        "    \"\"\"\n",
        "    Steepest Descent method for function minimization.\n",
        "\n",
        "    Parameters:\n",
        "    - func: The function to minimize.\n",
        "    - grad: The gradient of the function.\n",
        "    - x0: Initial guess (numpy array).\n",
        "    - tol: Tolerance for stopping criteria.\n",
        "    - max_iter: Maximum number of iterations.\n",
        "\n",
        "    Returns:\n",
        "    - x: The estimated minimum point.\n",
        "    - fval: The function value at the minimum point.\n",
        "    - n_iter: Number of iterations performed.\n",
        "    \"\"\"\n",
        "    x = np.array(x0, dtype=float)\n",
        "    n_iter = 0\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        g = grad(x)\n",
        "        if np.linalg.norm(g) < tol:\n",
        "            break\n",
        "\n",
        "        # Steepest descent direction\n",
        "        p = -g\n",
        "\n",
        "        # Line search for an appropriate step size\n",
        "        alpha = line_search(func, grad, x, p)\n",
        "\n",
        "        x = x + alpha * p\n",
        "        n_iter += 1\n",
        "\n",
        "    fval = func(x)\n",
        "    return x, fval, n_iter\n",
        "\n",
        "def line_search(func, grad, x, p, alpha0=1.0, c=1e-4, tau=0.9):\n",
        "    \"\"\"\n",
        "    Backtracking line search to find an appropriate step size.\n",
        "\n",
        "    Parameters:\n",
        "    - func: The function to minimize.\n",
        "    - grad: The gradient of the function.\n",
        "    - x: Current point.\n",
        "    - p: Search direction.\n",
        "    - alpha0: Initial step size.\n",
        "    - c: Parameter for Armijo condition.\n",
        "    - tau: Reduction factor for step size.\n",
        "\n",
        "    Returns:\n",
        "    - alpha: Step size.\n",
        "    \"\"\"\n",
        "    alpha = alpha0\n",
        "    while func(x + alpha * p) > func(x) + c * alpha * grad(x).dot(p):\n",
        "        alpha *= tau\n",
        "    return alpha\n",
        "\n",
        "\n",
        "\n",
        "x0 = [0.0, 0.0]\n",
        "min_point, min_value, iterations = steepest_descent(example_func, example_grad, x0)\n",
        "\n",
        "print(f\"Steepest Descent Method:\")\n",
        "print(f\"Minimum point: {min_point}\")\n",
        "print(f\"Minimum value: {min_value}\")\n",
        "print(f\"Iterations: {iterations}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuNl_ra8GLDY"
      },
      "source": [
        "# Q2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRci3TW5GMvr",
        "outputId": "2b4bb2a5-d2f7-47fd-c44b-8695b4759b59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fibonacci Search Method:\n",
            "Minimum point: [0. 0.]\n",
            "Minimum value: 512.0\n"
          ]
        }
      ],
      "source": [
        "# q2(b)\n",
        "import numpy as np\n",
        "\n",
        "def fibonacci_search(func, direction, x0, tol=.001, max_fib_idx=100):\n",
        "    \"\"\"\n",
        "    Fibonacci search method for one-dimensional function minimization along a direction.\n",
        "\n",
        "    Parameters:\n",
        "    - func: The function to minimize.\n",
        "    - direction: The direction vector for the line search.\n",
        "    - x0: Initial point (numpy array).\n",
        "    - tol: Tolerance for stopping criteria.\n",
        "    - max_fib_idx: Maximum index for Fibonacci sequence to avoid overflow.\n",
        "\n",
        "    Returns:\n",
        "    - x: The estimated minimum point in 2D space.\n",
        "    - fval: The function value at the minimum point.\n",
        "    \"\"\"\n",
        "    def f_1d(alpha):\n",
        "        return func(x0 + alpha * direction)\n",
        "\n",
        "    # Precompute Fibonacci numbers\n",
        "    fib = [0, 1]\n",
        "    for i in range(2, max_fib_idx + 1):\n",
        "        fib.append(fib[-1] + fib[-2])\n",
        "\n",
        "    # Find n such that fib[n] is the largest Fibonacci number less than (b-a)/tol\n",
        "    n = 0\n",
        "    while fib[n] < (1 / tol):\n",
        "        n += 1\n",
        "\n",
        "    a, b = 0, 1  # Initial interval, this can be adjusted based on the problem\n",
        "    x1 = a + (fib[n-2] / fib[n]) * (b - a)\n",
        "    x2 = a + (fib[n-1] / fib[n]) * (b - a)\n",
        "    f1 = f_1d(x1)\n",
        "    f2 = f_1d(x2)\n",
        "\n",
        "    for k in range(1, n):\n",
        "        if f1 > f2:\n",
        "            a = x1\n",
        "            x1 = x2\n",
        "            f1 = f2\n",
        "            x2 = a + (fib[n-k-1] / fib[n-k]) * (b - a)\n",
        "            f2 = f_1d(x2)\n",
        "        else:\n",
        "            b = x2\n",
        "            x2 = x1\n",
        "            f2 = f1\n",
        "            x1 = a + (fib[n-k-2] / fib[n-k]) * (b - a)\n",
        "            f1 = f_1d(x1)\n",
        "\n",
        "    if f1 < f2:\n",
        "        alpha = x1\n",
        "    else:\n",
        "        alpha = x2\n",
        "\n",
        "    return x0 + alpha * direction, f_1d(alpha)\n",
        "\n",
        "# Example function\n",
        "def q2_func(x):\n",
        "    return (x[0]-x[1]**3)**2 + 2*(x[0]-x[1]-4)**4\n",
        "\n",
        "x0 = np.array([0.0, 0.0])\n",
        "direction = np.array([1.0, 1.0])  # Example direction\n",
        "min_point, min_value = fibonacci_search(q2_func, direction, x0)\n",
        "\n",
        "print(f\"Fibonacci Search Method:\")\n",
        "print(f\"Minimum point: {min_point}\")\n",
        "print(f\"Minimum value: {min_value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-XovwZ_DpLe",
        "outputId": "a5708dc2-f65a-4bf9-f293-05b2d029d439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Golden Section Search Method:\n",
            "Minimum point: [3.32187398e-07 3.32187398e-07]\n",
            "Minimum value: 512.0000000000001\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def golden_section_search(func, direction, x0, tol=1e-6):\n",
        "    \"\"\"\n",
        "    Golden Section search method for one-dimensional function minimization along a direction.\n",
        "\n",
        "    Parameters:\n",
        "    - func: The function to minimize.\n",
        "    - direction: The direction vector for the line search.\n",
        "    - x0: Initial point (numpy array).\n",
        "    - tol: Tolerance for stopping criteria.\n",
        "\n",
        "    Returns:\n",
        "    - x: The estimated minimum point in 2D space.\n",
        "    - fval: The function value at the minimum point.\n",
        "    \"\"\"\n",
        "    def f_1d(alpha):\n",
        "        return func(x0 + alpha * direction)\n",
        "\n",
        "    # Define the interval for alpha\n",
        "    a, b = 0, 1  # Initial interval, this can be adjusted based on the problem\n",
        "\n",
        "    phi = (1 + np.sqrt(5)) / 2\n",
        "    resphi = 2 - phi\n",
        "\n",
        "    x1 = a + resphi * (b - a)\n",
        "    x2 = b - resphi * (b - a)\n",
        "    f1 = f_1d(x1)\n",
        "    f2 = f_1d(x2)\n",
        "\n",
        "    while abs(b - a) > tol:\n",
        "        if f1 < f2:\n",
        "            b = x2\n",
        "            x2 = x1\n",
        "            f2 = f1\n",
        "            x1 = a + resphi * (b - a)\n",
        "            f1 = f_1d(x1)\n",
        "        else:\n",
        "            a = x1\n",
        "            x1 = x2\n",
        "            f1 = f2\n",
        "            x2 = b - resphi * (b - a)\n",
        "            f2 = f_1d(x2)\n",
        "\n",
        "    if f1 < f2:\n",
        "        alpha = x1\n",
        "    else:\n",
        "        alpha = x2\n",
        "\n",
        "    return x0 + alpha * direction, f_1d(alpha)\n",
        "\n",
        "x0 = np.array([0.0, 0.0])\n",
        "direction = np.array([1.0, 1.0])  # Example direction\n",
        "min_point, min_value = golden_section_search(q2_func, direction, x0)\n",
        "\n",
        "print(f\"Golden Section Search Method:\")\n",
        "print(f\"Minimum point: {min_point}\")\n",
        "print(f\"Minimum value: {min_value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO5Eo34oGMsY",
        "outputId": "42fc03f5-c3c5-4f2f-82b5-1390a880dd8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.00028003358207258236 0.0004531038537848216\n",
            "Golden Section Search Method:\n",
            "Minimum point: [4.99943993 4.00028003]\n",
            "Minimum value: 3644.8340432497143\n"
          ]
        }
      ],
      "source": [
        "# q2(c)\n",
        "import numpy as np\n",
        "\n",
        "def golden_section_search(func, direction, x0, tol=1e-3):\n",
        "    def f_1d(alpha):\n",
        "        return func(x0 + alpha * direction)\n",
        "\n",
        "    # Define the interval for alpha\n",
        "    a, b = 0, 1  # Initial interval, this can be adjusted based on the problem\n",
        "\n",
        "    phi = (1 + np.sqrt(5)) / 2\n",
        "    resphi = 2 - phi\n",
        "\n",
        "    x1 = a + resphi * (b - a)\n",
        "    x2 = b - resphi * (b - a)\n",
        "    f1 = f_1d(x1)\n",
        "    f2 = f_1d(x2)\n",
        "\n",
        "    while abs(b - a) > tol:\n",
        "        if f1 < f2:\n",
        "            b = x2\n",
        "            x2 = x1\n",
        "            f2 = f1\n",
        "            x1 = a + resphi * (b - a)\n",
        "            f1 = f_1d(x1)\n",
        "        else:\n",
        "            a = x1\n",
        "            x1 = x2\n",
        "            f1 = f2\n",
        "            x2 = b - resphi * (b - a)\n",
        "            f2 = f_1d(x2)\n",
        "        if a<-2 or b>2:\n",
        "          print('warning')\n",
        "          break\n",
        "\n",
        "    if f1 < f2:\n",
        "        alpha = x1\n",
        "    else:\n",
        "        alpha = x2\n",
        "\n",
        "    print(x1,x2)\n",
        "\n",
        "    return x0 + alpha * direction, f_1d(alpha)\n",
        "\n",
        "\n",
        "# Example function\n",
        "def q2_func(x):\n",
        "    return (x[0]-x[1]**3)**2 + 2*(x[0]-x[1]-4)**4\n",
        "\n",
        "x0 = np.array([5, 4])\n",
        "direction = np.array([-2.0, 1.0])  # Example direction\n",
        "min_point, min_value = golden_section_search(q2_func, direction, x0)\n",
        "\n",
        "print(f\"Golden Section Search Method:\")\n",
        "print(f\"Minimum point: {min_point}\")\n",
        "print(f\"Minimum value: {min_value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "B0eLUNGaO7-2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0: a=-3, b=6, m=1.5, f_prime(m)=5.0\n",
            "Iteration 1: a=-3, b=1.5, m=-0.75, f_prime(m)=0.5\n",
            "Iteration 2: a=-3, b=-0.75, m=-1.875, f_prime(m)=-1.75\n",
            "Iteration 3: a=-1.875, b=-0.75, m=-1.3125, f_prime(m)=-0.625\n",
            "Iteration 4: a=-1.3125, b=-0.75, m=-1.03125, f_prime(m)=-0.0625\n",
            "Iteration 5: a=-1.03125, b=-0.75, m=-0.890625, f_prime(m)=0.21875\n",
            "Approximated root: x = -0.960938\n"
          ]
        }
      ],
      "source": [
        "# C6.2.1 p17\n",
        "import numpy as np\n",
        "def my_bisection(f_prime, a, b, tol , max_iterations=6):\n",
        "    \"\"\"\n",
        "    Approximates a root of the function f within the interval [a, b]\n",
        "    to within a specified tolerance |f(a+b/2)| < tol.\n",
        "\n",
        "    Args:\n",
        "        f: The function for which we want to find the root.\n",
        "        a, b: Interval endpoints.\n",
        "        tol: Tolerance (desired accuracy).\n",
        "\n",
        "    Returns:\n",
        "        Approximated root.\n",
        "    \"\"\"\n",
        "    # Check if a and b bound a root\n",
        "    # if f(a) * f(b) >= 0:\n",
        "    #     raise Exception(\"The scalars a and b do not bound a root\")\n",
        "    i = 0\n",
        "    while abs((b-a) / 2) >= tol:\n",
        "    # for i in range(max_iterations):\n",
        "        m = (a + b) / 2  # Midpoint\n",
        "        # print(f'The midpoint: {m}, minimum value: {quadratic_function(m)},f_prime(m)={f_prime(m)}')\n",
        "        print(f'Iteration {i}: a={a}, b={b}, m={m}, f_prime(m)={f_prime(m)}')\n",
        "        if f_prime(m) < 0:\n",
        "            a = m  # Update b\n",
        "        else:\n",
        "            b = m  # Update a\n",
        "        i+=1\n",
        "        if f_prime(m)==0 or i == max_iterations:\n",
        "            break\n",
        "    return (a + b) / 2\n",
        "\n",
        "def quadratic_function(x):\n",
        "    return x**2 + 2*x\n",
        "\n",
        "def derivative_quadratic(x):\n",
        "    return 2*x +2\n",
        "\n",
        "# Find the root of the quadratic function within [0, 2] with tolerance 0.01\n",
        "root_approx = my_bisection(derivative_quadratic, -3, 6, .11)\n",
        "print(f\"Approximated root: x = {root_approx:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
